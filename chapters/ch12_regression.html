<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    
    <title>12. An Application: Solving a Simple Regression Problem &#8212; Programming with Python for Engineers 1.0 documentation</title>

    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/d2l.css" />
    <link rel="stylesheet" href="../_static/material-design-lite-1.3.0/material.blue-deep_orange.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx_materialdesign_theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fontawesome/all.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fonts.css" type="text/css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/d2l.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="../_static/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="11. An Application: Approximation and Optimization" href="ch11_application_optimization.html" /> 
  </head>
<body>
    <div class="mdl-layout mdl-js-layout mdl-layout--fixed-header mdl-layout--fixed-drawer"><header class="mdl-layout__header mdl-layout__header--waterfall ">
    <div class="mdl-layout__header-row">
        
        <nav class="mdl-navigation breadcrumb">
            <a class="mdl-navigation__link is-active"><span class="section-number">12. </span>An Application: Solving a Simple Regression Problem</a>
        </nav>
        <div class="mdl-layout-spacer"></div>
        <nav class="mdl-navigation">
        
<form class="form-inline pull-sm-right" action="../search.html" method="get">
      <div class="mdl-textfield mdl-js-textfield mdl-textfield--expandable mdl-textfield--floating-label mdl-textfield--align-right">
        <label id="quick-search-icon" class="mdl-button mdl-js-button mdl-button--icon"  for="waterfall-exp">
          <i class="material-icons">search</i>
        </label>
        <div class="mdl-textfield__expandable-holder">
          <input class="mdl-textfield__input" type="text" name="q"  id="waterfall-exp" placeholder="Search" />
          <input type="hidden" name="check_keywords" value="yes" />
          <input type="hidden" name="area" value="default" />
        </div>
      </div>
      <div class="mdl-tooltip" data-mdl-for="quick-search-icon">
      Quick search
      </div>
</form>
        
<a id="button-show-source"
    class="mdl-button mdl-js-button mdl-button--icon"
    href="../_sources/chapters/ch12_regression.rst.txt" rel="nofollow">
  <i class="material-icons">code</i>
</a>
<div class="mdl-tooltip" data-mdl-for="button-show-source">
Show Source
</div>
        </nav>
    </div>
    <div class="mdl-layout__header-row header-links">
      <div class="mdl-layout-spacer"></div>
      <nav class="mdl-navigation">
          
              <a  class="mdl-navigation__link" href="https://pp4e-book.github.io/pp4e-book.pdf">
                  <i class="fas fa-file-pdf"></i>
                  PDF
              </a>
          
              <a  class="mdl-navigation__link" href="https://github.com/pp4e-book/source">
                  <i class="fab fa-github"></i>
                  Github
              </a>
          
              <a  class="mdl-navigation__link" href="https://pp4e-book.github.io/chapters/all_notebooks.zip">
                  <i class="fas fa-download"></i>
                  All Notebooks
              </a>
          
              <a  class="mdl-navigation__link" href="https://ceng240.github.io/">
                  <i class="fas fa-user-graduate"></i>
                  Course
              </a>
      </nav>
    </div>
</header><header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <img class="logo" src="../_static/logo-with-text.png" alt="Programming with Python for Engineers"/>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul>
<li class="toctree-l1"><a class="reference internal" href="ch0_preface.html">Preface</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="ch1_computer_organization.html">1. Basic Computer Organization</a></li>
<li class="toctree-l1"><a class="reference internal" href="ch2_programming.html">2. A Broad Look at Programming and Programming Languages</a></li>
<li class="toctree-l1"><a class="reference internal" href="ch3_data_representation.html">3. Representation of Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="ch4_dive_into_python.html">4. Dive into Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="ch5_conditional_and_repetitive.html">5. Conditional and Repetitive Execution</a></li>
<li class="toctree-l1"><a class="reference internal" href="ch6_functions.html">6. Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="ch7_OOP.html">7. A Gentle Introduction to Object-Oriented Programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="ch8_file_handling.html">8. File Handling</a></li>
<li class="toctree-l1"><a class="reference internal" href="ch9_error_handling.html">9. Error Handling and Debugging</a></li>
<li class="toctree-l1"><a class="reference internal" href="ch10_scientific_libraries.html">10. Scientific and Engineering Libraries</a></li>
<li class="toctree-l1"><a class="reference internal" href="ch11_application_optimization.html">11. An Application: Approximation and Optimization</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">12. An Application: Solving a Simple Regression Problem</a></li>
</ul>

            </nav>
        
        </div>
    
</header>
        <main class="mdl-layout__content" tabIndex="0">

	<script type="text/javascript" src="../_static/sphinx_materialdesign_theme.js "></script>
    <header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <img class="logo" src="../_static/logo-with-text.png" alt="Programming with Python for Engineers"/>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul>
<li class="toctree-l1"><a class="reference internal" href="ch0_preface.html">Preface</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="ch1_computer_organization.html">1. Basic Computer Organization</a></li>
<li class="toctree-l1"><a class="reference internal" href="ch2_programming.html">2. A Broad Look at Programming and Programming Languages</a></li>
<li class="toctree-l1"><a class="reference internal" href="ch3_data_representation.html">3. Representation of Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="ch4_dive_into_python.html">4. Dive into Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="ch5_conditional_and_repetitive.html">5. Conditional and Repetitive Execution</a></li>
<li class="toctree-l1"><a class="reference internal" href="ch6_functions.html">6. Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="ch7_OOP.html">7. A Gentle Introduction to Object-Oriented Programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="ch8_file_handling.html">8. File Handling</a></li>
<li class="toctree-l1"><a class="reference internal" href="ch9_error_handling.html">9. Error Handling and Debugging</a></li>
<li class="toctree-l1"><a class="reference internal" href="ch10_scientific_libraries.html">10. Scientific and Engineering Libraries</a></li>
<li class="toctree-l1"><a class="reference internal" href="ch11_application_optimization.html">11. An Application: Approximation and Optimization</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">12. An Application: Solving a Simple Regression Problem</a></li>
</ul>

            </nav>
        
        </div>
    
</header>

    <div class="document">
        <div class="page-content" role="main">
        
  <div class="section" id="an-application-solving-a-simple-regression-problem">
<h1><span class="section-number">12. </span>An Application: Solving a Simple Regression Problem<a class="headerlink" href="#an-application-solving-a-simple-regression-problem" title="Permalink to this headline">Â¶</a><a href="https://colab.research.google.com/github/pp4e-book/pp4e-book.github.io/blob/master/chapters/ch12_regression.ipynb" onclick="captureOutboundLink('https://colab.research.google.com/github/['pp4e-book/pp4e-book.github.io']/blob/master/chapters/ch12_regression.ipynb'); return false;"> <button style="float:right", id="Colab" class="mdl-button mdl-js-button mdl-button--primary mdl-js-ripple-effect"> <i class=" fas fa-external-link-alt"></i> Colab </button></a><div class="mdl-tooltip" data-mdl-for="Colab"> Open the notebook in Colab</div></h1>
<p><em>(C) Copyright Notice: This chapter is part of the book available
at</em><a class="reference external" href="https://pp4e-book.github.io/">https://pp4e-book.github.io/</a><em>and copying, distributing, modifying
it requires explicit permission from the authors. See the book page for
details:</em><a class="reference external" href="https://pp4e-book.github.io/">https://pp4e-book.github.io/</a></p>
<p>In this chapter, we will cover an important problem in many disciplines:
that of fitting (regressing) a function to a set of data, i.e.Â the
regression problem. We will look at two versions, namely, linear
regression and non-linear regression, using SciPy. While doing so, we
will use Pandas, NumPy and Matplotlib as well, which were covered in
Chapter 10.</p>
<div class="section" id="introduction">
<h2><span class="section-number">12.1. </span>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">Â¶</a></h2>
<p>Let us first formulate the problem and clearly outline the notation. In
a regression problem, we have a set of <span class="math notranslate nohighlight">\(x,y\)</span> values:
<span class="math notranslate nohighlight">\(\{(x_0, y_0), (x_1, y_1), ..., (x_n, y_n)\}\)</span>, where <span class="math notranslate nohighlight">\(x_i\)</span>
and <span class="math notranslate nohighlight">\(y_i\)</span> can be multi-dimensional variables (i.e.Â vectors) but
for the sake of simplicity, in this chapter we will work with
one-dimensional <span class="math notranslate nohighlight">\(x_i\)</span> and <span class="math notranslate nohighlight">\(y_i\)</span> values. In a regression
problem, we are interested in finding the function <span class="math notranslate nohighlight">\(f()\)</span> that goes
through those <span class="math notranslate nohighlight">\((x_i, y_i)\)</span> values. In other words, we wish to find
<span class="math notranslate nohighlight">\(f()\)</span> that satisfies the following:</p>
<div class="math notranslate nohighlight" id="equation-chapters-ch12-regression-0">
<span class="eqno">(12.1.1)<a class="headerlink" href="#equation-chapters-ch12-regression-0" title="Permalink to this equation">Â¶</a></span>\[y_i = f(x_i).\]</div>
<p>At first, this might look difficult since we are trying to estimate a
function from its input-output values and there can be infinitely many
functions that can go through a finite set of <span class="math notranslate nohighlight">\((x_i, y_i)\)</span> values.
However, by restructuring the problem a little bit and making some
assumptions on the general form of <span class="math notranslate nohighlight">\(f()\)</span>, we can solve such
complicated regression problems very well.</p>
<p>Let us briefly describe how we can do so: We first re-write <span class="math notranslate nohighlight">\(f()\)</span>
as a parametric function and try to formulate the regression problem as
the problem of finding the parameters of <span class="math notranslate nohighlight">\(f()\)</span>:</p>
<div class="math notranslate nohighlight" id="equation-chapters-ch12-regression-1">
<span class="eqno">(12.1.2)<a class="headerlink" href="#equation-chapters-ch12-regression-1" title="Permalink to this equation">Â¶</a></span>\[y = f(x) = f(x;\mathbf{\theta}) = \sum_{i=1}^{m} g_i(x; \theta_i),\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{\theta}=(\theta_1, ..., \theta_n)\)</span> is the set of
parameters that we need to find to solve the regression problem; and
<span class="math notranslate nohighlight">\(g_1(), ..., g_m()\)</span> are our âsimplerâ functions (compared to
<span class="math notranslate nohighlight">\(f()\)</span>) whose parameters can be identified more easily compared to
<span class="math notranslate nohighlight">\(f()\)</span>.</p>
<p>With this parameterized definition of <span class="math notranslate nohighlight">\(f()\)</span>, we can formally
define regression as an optimization (minimization) problem (see also
Chapter 11):</p>
<div class="math notranslate nohighlight" id="equation-chapters-ch12-regression-2">
<span class="eqno">(12.1.3)<a class="headerlink" href="#equation-chapters-ch12-regression-2" title="Permalink to this equation">Â¶</a></span>\[\theta^* \leftarrow  \arg\min_{\theta\in\mathbb{R}^d} \sum_i \left(y_i - f(x_i; \theta)\right)^2,\]</div>
<p>where the summation runs over the
<span class="math notranslate nohighlight">\((x_0, y_0), (x_1, y_1), ..., (x_n, y_n)\)</span> values that we are
trying to regress; <span class="math notranslate nohighlight">\(\left(y_i - f(x_i; \theta)\right)^2\)</span> is the
error between the estimated (regressed) value
(i.e.Â <span class="math notranslate nohighlight">\(f(x_i; \theta)\)</span>) and the correct <span class="math notranslate nohighlight">\(y_i\)</span> value with
<span class="math notranslate nohighlight">\(\theta\)</span> as the parameters.</p>
<p>We can describe this optimization formulation in words as: Find
parameters <span class="math notranslate nohighlight">\(\theta\)</span> that minimize the error between <span class="math notranslate nohighlight">\(y_i\)</span>
and what the function is predicting given <span class="math notranslate nohighlight">\(x_i\)</span> as input.</p>
<p>This is a minimization problem and in Chapter 11, we have seen a simple
solution and how SciPy can be used for such problems. In this chapter,
we will spend more time on this with sample regression problems and
solutions. Namely,</p>
<ul class="simple">
<li><p>Linear regression, where <span class="math notranslate nohighlight">\(f()\)</span> is assumed to be a line,
<span class="math notranslate nohighlight">\(y=ax+b\)</span>, and <span class="math notranslate nohighlight">\(\theta\)</span> is <span class="math notranslate nohighlight">\((a,b)\)</span>.</p></li>
<li><p>Non-linear regression, where <span class="math notranslate nohighlight">\(f()\)</span> has a non-linear nature,
e.g.Â a quadratic, exponential or logarithmic form.</p></li>
</ul>
<div class="section" id="why-is-regression-important">
<h3><span class="section-number">12.1.1. </span>Why is regression important?<a class="headerlink" href="#why-is-regression-important" title="Permalink to this headline">Â¶</a></h3>
<p>In many disciplines, we observe an environment, an event, or an entity
through sensors or some data collected in a different manner, and obtain
some information about what we are observing in the form of a variable
<span class="math notranslate nohighlight">\(x\)</span>. Each <span class="math notranslate nohighlight">\(x\)</span> generally has an associated outcome variable
<span class="math notranslate nohighlight">\(y\)</span>. Or <span class="math notranslate nohighlight">\(x\)</span> can represent an action that we are exerting in
an environment and we are interested in finding how <span class="math notranslate nohighlight">\(x\)</span> affects
the environment by observing a variable <span class="math notranslate nohighlight">\(y\)</span>.</p>
<p>Here are some examples for <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span> for which finding a
function <span class="math notranslate nohighlight">\(f()\)</span> can be really useful:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x\)</span>: The current that we are providing to a motor. <span class="math notranslate nohighlight">\(y\)</span>:
The speed of the motor.</p></li>
<li><p><span class="math notranslate nohighlight">\(x\)</span>: The day of a year. <span class="math notranslate nohighlight">\(y\)</span>: The average rain fall on a
year.</p></li>
<li><p><span class="math notranslate nohighlight">\(x\)</span>: The changes in stock value of a bond in the last day.
<span class="math notranslate nohighlight">\(y\)</span>: The value of a bond in one hour.</p></li>
<li><p><span class="math notranslate nohighlight">\(x\)</span>: The number of COVID cases in a day. <span class="math notranslate nohighlight">\(y\)</span>: The number
of deaths owing to COVID.</p></li>
</ul>
</div>
<div class="section" id="the-form-of-the-function">
<h3><span class="section-number">12.1.2. </span>The form of the function<a class="headerlink" href="#the-form-of-the-function" title="Permalink to this headline">Â¶</a></h3>
<p>As discussed before, solving the regression problem without making any
assumption about the underlying function is very challenging. We can
simplify the problem by making an assumption about the function.
However, an incorrect assumption can yield inaccurate regression model.</p>
<p>This is illustrated very well in a famous cartoon in
<a class="reference internal" href="#ch12-xkcd"><span class="std std-numref">Fig. 12.1.1</span></a>. As illustrated, if the form of the function is
too simple (e.g.Â linear), the fitted function will not be able to
capture the true nature of the data. However, if the assumed function
form is too complex (e.g.Â a higher-order polynomial), the fitted
function will try to go through every data point, which may not be ideal
since the data can be noisy.</p>
<p>Choosing the right form of the function is therefore tricky and it
requires some prior idea about the function or the problem. If the
relationship between <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span> is known to be linear, then
a linear function form should be chosen. If the relation between
<span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span> is known to be non-linear but the exact form is
unknown, <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span> can be plotted first to get a feeling
for the underlying form. This can give an idea for what kinds of
function forms can be suitable.</p>
<div class="figure align-default" id="id3">
<span id="ch12-xkcd"></span><img alt="../_images/ch12_curve_fitting.png" src="../_images/ch12_curve_fitting.png" />
<p class="caption"><span class="caption-number">Fig. 12.1.1 </span><span class="caption-text">The challenging regression problem can be simplified by making an
assumption about the underlying function; as illustrated in the
drawings, the function can be assumed to be linear, quadratic,
logarithmic etc. However, an incorrect assumption can yield
inaccurate regression. (Figure source: <a class="reference external" href="https://xkcd.com/2048/">https://xkcd.com/2048/</a>)</span><a class="headerlink" href="#id3" title="Permalink to this image">Â¶</a></p>
</div>
</div>
</div>
<div class="section" id="least-squares-regression">
<h2><span class="section-number">12.2. </span>Least-Squares Regression<a class="headerlink" href="#least-squares-regression" title="Permalink to this headline">Â¶</a></h2>
<p>A commonly-used method for regression is called Least-Squares Regression
(LSE). In LSE, the minimization problem in Section 12.1 is solved by
setting the gradient of the objective to zero:</p>
<div class="math notranslate nohighlight" id="equation-chapters-ch12-regression-3">
<span class="eqno">(12.2.1)<a class="headerlink" href="#equation-chapters-ch12-regression-3" title="Permalink to this equation">Â¶</a></span>\[\frac{\partial}{\partial \theta_j} \sum_i \left(y_i - f(x_i; \theta)\right)^2 = 0, \quad \textrm{for each } j.\]</div>
<p><strong>Linear Least-Squares Regression</strong>. If our function is linear,
i.e.Â <span class="math notranslate nohighlight">\(f(x_i; \theta) = \theta_1 x_i + \theta_2\)</span>, setting the
gradient to zero provides us one set of equations for each
<span class="math notranslate nohighlight">\(\theta_j\)</span>. If the number of data points (<span class="math notranslate nohighlight">\(x_i, y_i\)</span>) is
bigger than the number of variables, these equations can be easily
solved to obtain <span class="math notranslate nohighlight">\(\mathbf{\theta}\)</span> that minimizes the objective in
Section 12.1. Those interested in the derivation of the solution and its
exact form can look up
e.g.Â <a class="reference external" href="https://en.wikipedia.org/wiki/Linear_least_squares">Wikipedia</a>.</p>
<p><strong>Non-linear Least-Squares Regression</strong>. If our function is not linear,
a solution can be obtained iteratively by making a linear
approximation/step at each iteration using the so-called <a class="reference external" href="https://en.wikipedia.org/wiki/Gauss%E2%80%93Newton_algorithm">Gauss-Newton
method</a>.</p>
</div>
<div class="section" id="linear-regression-with-scipy">
<h2><span class="section-number">12.3. </span>Linear Regression with SciPy<a class="headerlink" href="#linear-regression-with-scipy" title="Permalink to this headline">Â¶</a></h2>
<p>SciPy has a function called <code class="docutils literal notranslate"><span class="pre">scipy.stats.linregress(x,</span> <span class="pre">y)</span></code> which we
can use to regress a line passing through a set of points. Let us go
through an example to see how we can do that. Moreover, we will use our
regressed line to analyze some properties of our data.</p>
<div class="section" id="create-artificial-data">
<h3><span class="section-number">12.3.1. </span>Create Artificial Data<a class="headerlink" href="#create-artificial-data" title="Permalink to this headline">Â¶</a></h3>
<p>To keep things simple, let us generate some artificial data in Python
and save it in a file called <code class="docutils literal notranslate"><span class="pre">ch12_linear_data_example.csv</span></code>. We have
already run this code and saved this CSV file on web â in the following
steps, we will continue with this file on the web. However, you can
change the following code the generate data in different forms and with
different noise levels and observe how the different regression methods
perform.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="k">def</span> <span class="nf">plot_func</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">legend</span><span class="p">):</span>
  <span class="n">ys</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="o">*</span><span class="n">params</span><span class="p">)</span> <span class="c1"># This is called parameter unpacking -- Google and learn this</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">legend</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">line_func</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Line function.&quot;&quot;&quot;</span>
  <span class="c1">#(a,b) = params</span>
  <span class="k">return</span> <span class="n">a</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="n">b</span>

<span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">ys</span> <span class="o">=</span> <span class="n">line_func</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">xs</span><span class="o">.</span><span class="n">size</span><span class="p">)</span> <span class="c1"># add random noise</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;x&#39;</span><span class="p">:</span> <span class="n">xs</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">:</span> <span class="n">ys</span><span class="p">})</span>
<span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;ch12_linear_data_example.csv&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Created </span><span class="si">{0}</span><span class="s2"> many data points and saved them into CSV file.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">xs</span><span class="o">.</span><span class="n">size</span><span class="p">))</span>
</pre></div>
</div>
<div class="output highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Created</span> <span class="mi">100</span> <span class="n">many</span> <span class="n">data</span> <span class="n">points</span> <span class="ow">and</span> <span class="n">saved</span> <span class="n">them</span> <span class="n">into</span> <span class="n">CSV</span> <span class="n">file</span><span class="o">.</span>
</pre></div>
</div>
</div>
<div class="section" id="download-and-visualize-data">
<h3><span class="section-number">12.3.2. </span>Download and Visualize Data<a class="headerlink" href="#download-and-visualize-data" title="Permalink to this headline">Â¶</a></h3>
<p>Let us download the <code class="docutils literal notranslate"><span class="pre">ch12_linear_data.csv</span></code> file from web so that we
can provide you the experience of a full data analysis pipeline.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span># Let us download our data
!wget -nc https://raw.githubusercontent.com/sinankalkan/CENG240/master/figures/ch12_linear_data.csv

# Import the necessary libraries
import pandas as pd

# Read the file named &#39;ch12_linear_data.csv&#39;
df = pd.read_csv(&#39;ch12_linear_data.csv&#39;)

# Print the CSV file&#39;s contents:
print(&quot;The CSV file contains the following:\n&quot;, df, &quot;\n&quot;)

# Check the types of each column
df.dtypes
</pre></div>
</div>
<div class="output highlight-default notranslate"><div class="highlight"><pre><span></span>--2021-06-21 20:22:34--  https://raw.githubusercontent.com/sinankalkan/CENG240/master/figures/ch12_linear_data.csv
Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...
Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 4049 (4.0K) [text/plain]
Saving to: âch12_linear_data.csvâ

ch12_linear_data.cs 100%[===================&gt;]   3.95K  --.-KB/s    in 0.002s

2021-06-21 20:22:35 (2.56 MB/s) - âch12_linear_data.csvâ saved [4049/4049]

The CSV file contains the following:
     Unnamed: 0          x          y
0            0 -10.000000 -29.198799
1            1  -9.797980 -33.379918
2            2  -9.595960 -25.661456
3            3  -9.393939 -24.037193
4            4  -9.191919 -25.264474
..         ...        ...        ...
95          95   9.191919  27.905021
96          96   9.393939  24.494575
97          97   9.595960  32.212389
98          98   9.797980  28.511129
99          99  10.000000  33.593768

[100 rows x 3 columns]
</pre></div>
</div>
<div class="output highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Unnamed</span><span class="p">:</span> <span class="mi">0</span>      <span class="n">int64</span>
<span class="n">x</span>             <span class="n">float64</span>
<span class="n">y</span>             <span class="n">float64</span>
<span class="n">dtype</span><span class="p">:</span> <span class="nb">object</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Let us visualize the data</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">xs</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">][:]</span><span class="o">.</span><span class="n">values</span>
<span class="n">ys</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">][:]</span><span class="o">.</span><span class="n">values</span>

<span class="c1"># Plot y vs. x</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">)</span>

<span class="c1"># Set the labels for x and y axes:</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>

<span class="c1"># Set the title of the figure</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;y vs x&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="output highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Text</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="s1">&#39;y vs x&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="figure align-default">
<img alt="../_images/output_ch12_regression_608a18_4_1.png" src="../_images/output_ch12_regression_608a18_4_1.png" />
</div>
<p>We see that our data is rather noisy, though it more or less follows a
linear function. Let us see whether we can capture that.</p>
</div>
<div class="section" id="fit-a-linear-function-with-scipy">
<h3><span class="section-number">12.3.3. </span>Fit a Linear Function with SciPy<a class="headerlink" href="#fit-a-linear-function-with-scipy" title="Permalink to this headline">Â¶</a></h3>
<p>Now, let us fit a line (linear function) to our data using
<code class="docutils literal notranslate"><span class="pre">scipy.stats.linregress</span></code>. The specific method being used by this
function is Least-Squares Regression which we briefly explained in
Section 12.2.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import stats module</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>

<span class="c1"># Fit a linear model:</span>
<span class="n">solution</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">linregress</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">)</span>

<span class="c1"># Get the slope (a) and the intercept (b) in y = ax + b</span>
<span class="n">a_estimated</span> <span class="o">=</span> <span class="n">solution</span><span class="o">.</span><span class="n">slope</span>
<span class="n">b_estimated</span> <span class="o">=</span> <span class="n">solution</span><span class="o">.</span><span class="n">intercept</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The estimated solution is: y = </span><span class="si">%4f</span><span class="s2"> x + </span><span class="si">%4f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">a_estimated</span><span class="p">,</span> <span class="n">b_estimated</span><span class="p">))</span>
</pre></div>
</div>
<div class="output highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">The</span> <span class="n">estimated</span> <span class="n">solution</span> <span class="ow">is</span><span class="p">:</span> <span class="n">y</span> <span class="o">=</span> <span class="mf">2.963812</span> <span class="n">x</span> <span class="o">+</span> <span class="mf">0.442237</span>
</pre></div>
</div>
</div>
<div class="section" id="analyze-the-solution">
<h3><span class="section-number">12.3.4. </span>Analyze the Solution<a class="headerlink" href="#analyze-the-solution" title="Permalink to this headline">Â¶</a></h3>
<p>We have obtained a solution. Now, let us analyze how good the solution
is. We can do that qualitatively (by visual inspection) or
quantitatively (by looking at some numerical measures of how good the
fit is).</p>
<p><strong>1- Qualitative Analysis</strong>. For regression, a qualitative analysis can
be performed by plotting the data, the obtained solution and the correct
solution. If the obtained solution goes through the data well and is
close to the original solution in the graph, then we can visually
confirm whether the solution looks acceptable.</p>
<p>Let us do this for our example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot y vs. x</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">)</span>

<span class="c1"># Plot the estimated line</span>
<span class="n">plot_func</span><span class="p">(</span><span class="n">line_func</span><span class="p">,</span> <span class="p">(</span><span class="n">a_estimated</span><span class="p">,</span> <span class="n">b_estimated</span><span class="p">),</span> <span class="n">xs</span><span class="p">,</span> <span class="s2">&quot;Estimated line&quot;</span><span class="p">)</span>

<span class="c1"># Plot the correct line</span>
<span class="c1"># The data was generated from y = 3x + 0.5</span>
<span class="n">a_correct</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">b_correct</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">plot_func</span><span class="p">(</span><span class="n">line_func</span><span class="p">,</span> <span class="p">(</span><span class="n">a_correct</span><span class="p">,</span> <span class="n">b_correct</span><span class="p">),</span> <span class="n">xs</span><span class="p">,</span> <span class="s2">&quot;Correct line&quot;</span><span class="p">)</span>

<span class="c1"># Set the labels for x and y axes:</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>

<span class="c1"># Set the title of the figure</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;y vs x&quot;</span><span class="p">)</span>

<span class="c1"># Legend</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
<div class="output highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">&lt;</span><span class="n">matplotlib</span><span class="o">.</span><span class="n">legend</span><span class="o">.</span><span class="n">Legend</span> <span class="n">at</span> <span class="mh">0x12e6d8d30</span><span class="o">&gt;</span>
</pre></div>
</div>
<div class="figure align-default">
<img alt="../_images/output_ch12_regression_608a18_8_1.png" src="../_images/output_ch12_regression_608a18_8_1.png" />
</div>
<p>We can confirm that the obtained solution (blue line) goes through the
original data points well and it is almost identical to the correct
line, i.e.Â the line from which we generated the original <span class="math notranslate nohighlight">\((x,y)\)</span>
pairs. So, our regression solution appears to be accurate visually.</p>
<p><strong>2- Quantitative Analysis</strong>. Qualitative analysis can be difficult
sometimes and its judgment is subjective; i.e.Â different observers might
draw different conclusions especially in cases where the solution is
different from the correct solution. Therefore, in addition to the
qualitative analysis like we did above, it is very common to measure the
goodness of our solution with a number.</p>
<p>Depending on the problem, different measures can be used. For
regression, we frequently use the following three:</p>
<ol class="arabic simple">
<li><p><em>Mean Squared Error (MSE)</em>. For <span class="math notranslate nohighlight">\(N\)</span> data points, assuming
<span class="math notranslate nohighlight">\(\hat{y}_i\)</span> is the predicted value for <span class="math notranslate nohighlight">\(x_i\)</span>, MSE can be
defined as follows:</p></li>
</ol>
<div class="math notranslate nohighlight" id="equation-chapters-ch12-regression-4">
<span class="eqno">(12.3.1)<a class="headerlink" href="#equation-chapters-ch12-regression-4" title="Permalink to this equation">Â¶</a></span>\[MSE = \frac{1}{N} \sum_{i=1}^N (y_i - \hat{y}_i)^2,\]</div>
<p>which essentially accumulates the squared errors for each data point.</p>
<ol class="arabic simple" start="2">
<li><p><em>Root Mean Squared Error (RMSE)</em>. RMSE is simply the square-root of
MSE:</p></li>
</ol>
<div class="math notranslate nohighlight" id="equation-chapters-ch12-regression-5">
<span class="eqno">(12.3.2)<a class="headerlink" href="#equation-chapters-ch12-regression-5" title="Permalink to this equation">Â¶</a></span>\[RMSE = \sqrt{\frac{1}{N} \sum_{i=1}^N (y_i - \hat{y}_i)^2}.\]</div>
<ol class="arabic simple" start="3">
<li><p><em>:math:`R^2` Error</em> (also called the coefficient of determination).
<span class="math notranslate nohighlight">\(R^2\)</span> is a normalized measure which considers the error of the
âcorrectâ solution as well. Since data can be noisy, this can be a
better way to understand how good/bad our error value (MSE or RMSE)
was. <span class="math notranslate nohighlight">\(R^2\)</span> Error is defined as:</p></li>
</ol>
<div class="math notranslate nohighlight" id="equation-chapters-ch12-regression-6">
<span class="eqno">(12.3.3)<a class="headerlink" href="#equation-chapters-ch12-regression-6" title="Permalink to this equation">Â¶</a></span>\[R^2 = 1 - \frac{\textrm{MSE of estimates}}{\textrm{MSE wrt. the mean of y}}
= 1 - \frac{1/N \sum_{i=1}^N (y_i - \hat{y}_i)^2}{1/N \sum_{i=1}^N (y_i - \overline{y}_i)^2} = 1 - \frac{\sum_{i=1}^N (y_i - \hat{y}_i)^2}{\sum_{i=1}^N (y_i - \overline{y})^2},\]</div>
<p>where <span class="math notranslate nohighlight">\(\overline{y}=1/N\sum_i y_i\)</span> is the mean of <span class="math notranslate nohighlight">\(y\)</span>
values. If <span class="math notranslate nohighlight">\(R^2=1\)</span>, that means MSE of the estimates is zero;
i.e.Â we have obtained perfect regression. If <span class="math notranslate nohighlight">\(R^2=0\)</span>, all
<span class="math notranslate nohighlight">\(y_i=\overline{y}\)</span>; in other words, all estimates are the mean of
the <span class="math notranslate nohighlight">\(y\)</span> values, therefore the regression method did not find a
good solution. If, on the other hand, <span class="math notranslate nohighlight">\(R^2&lt;0\)</span>, that means the
obtained solution is even worse than the mean <span class="math notranslate nohighlight">\(y_i\)</span> values.</p>
<p>Now let us analyze our solution using these three metrics.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">MSE</span><span class="p">(</span><span class="n">estimated_y</span><span class="p">,</span> <span class="n">correct_y</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Mean Squared Error between the estimated_y and correct_y values.</span>
<span class="sd">    Inputs are both numpy arrays.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">result</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">N</span> <span class="o">=</span> <span class="n">estimated_y</span><span class="o">.</span><span class="n">size</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">+=</span> <span class="p">(</span><span class="n">estimated_y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">correct_y</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">**</span> <span class="mi">2</span>
  <span class="k">return</span> <span class="n">result</span> <span class="o">/</span> <span class="n">N</span>

<span class="k">def</span> <span class="nf">RMSE</span><span class="p">(</span><span class="n">estimated_y</span><span class="p">,</span> <span class="n">correct_y</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Root Mean Squared Error between the estimated_y and correct_y values.</span>
<span class="sd">    Inputs are both numpy arrays.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="n">MSE</span><span class="p">(</span><span class="n">estimated_y</span><span class="p">,</span> <span class="n">correct_y</span><span class="p">)</span> <span class="o">**</span> <span class="mf">0.5</span>

<span class="k">def</span> <span class="nf">R_squared</span><span class="p">(</span><span class="n">estimated_y</span><span class="p">,</span> <span class="n">correct_y</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    R^2 error between the estimated_y and correct_y values.</span>
<span class="sd">    Inputs are both numpy arrays.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">MSE_of_estimates</span> <span class="o">=</span> <span class="n">MSE</span><span class="p">(</span><span class="n">estimated_y</span><span class="p">,</span> <span class="n">correct_y</span><span class="p">)</span>
  <span class="n">mean_y</span> <span class="o">=</span> <span class="n">correct_y</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
  <span class="n">mean_y_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">correct_y</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">mean_y</span><span class="p">)</span>
  <span class="n">MSE_wrt_mean_of_y</span> <span class="o">=</span> <span class="n">MSE</span><span class="p">(</span><span class="n">estimated_y</span><span class="p">,</span> <span class="n">mean_y_array</span><span class="p">)</span> <span class="c1"># an array filled with mean-y</span>
  <span class="n">result</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">MSE_of_estimates</span> <span class="o">/</span> <span class="n">MSE_wrt_mean_of_y</span>

  <span class="k">return</span> <span class="n">result</span>

<span class="n">estimated_y</span> <span class="o">=</span> <span class="n">xs</span> <span class="o">*</span> <span class="n">a_estimated</span> <span class="o">+</span> <span class="n">b_estimated</span>
<span class="n">correct_y</span> <span class="o">=</span> <span class="n">ys</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MSE Error: &quot;</span><span class="p">,</span> <span class="n">MSE</span><span class="p">(</span><span class="n">estimated_y</span><span class="p">,</span> <span class="n">correct_y</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;RMSE Error: &quot;</span><span class="p">,</span> <span class="n">RMSE</span><span class="p">(</span><span class="n">estimated_y</span><span class="p">,</span> <span class="n">correct_y</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;R-squared Error: &quot;</span><span class="p">,</span> <span class="n">R_squared</span><span class="p">(</span><span class="n">estimated_y</span><span class="p">,</span> <span class="n">correct_y</span><span class="p">))</span>
</pre></div>
</div>
<div class="output highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">MSE</span> <span class="n">Error</span><span class="p">:</span>  <span class="mf">14.710406962785715</span>
<span class="n">RMSE</span> <span class="n">Error</span><span class="p">:</span>  <span class="mf">3.835414835814467</span>
<span class="n">R</span><span class="o">-</span><span class="n">squared</span> <span class="n">Error</span><span class="p">:</span>  <span class="mf">0.950755415581623</span>
</pre></div>
</div>
<p>We see that we have obtained very low errors. Especially the <span class="math notranslate nohighlight">\(R^2\)</span>
value is very close to one, which suggests good approximation of the
regressed line to the underlying solution. Note that since our data was
noisy, it was not possible to obtain <span class="math notranslate nohighlight">\(R^2 = 1\)</span>.</p>
</div>
</div>
<div class="section" id="non-linear-regression-with-scipy">
<h2><span class="section-number">12.4. </span>Non-linear Regression with SciPy<a class="headerlink" href="#non-linear-regression-with-scipy" title="Permalink to this headline">Â¶</a></h2>
<p>Let us now see how we can perform non-linear regression.</p>
<div class="section" id="id1">
<h3><span class="section-number">12.4.1. </span>Create Artificial Data<a class="headerlink" href="#id1" title="Permalink to this headline">Â¶</a></h3>
<p>To keep things simple, let us generate some artificial data in Python
and save it in a file called <code class="docutils literal notranslate"><span class="pre">ch12_nonlinear_data_example.csv</span></code>. We
have already run this code and saved this CSV file on web â in the
following steps, we will continue with this file on the web. However,
you can change the following code the generate data in different forms
and with different noise levels and observe how the different regression
methods perform.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="k">def</span> <span class="nf">nonlinear_f</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
  <span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">)</span> <span class="o">=</span> <span class="n">params</span>
  <span class="k">return</span> <span class="n">a</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span><span class="o">+</span><span class="n">b</span>

<span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">ys</span> <span class="o">=</span> <span class="n">nonlinear_f</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="n">xs</span><span class="o">.</span><span class="n">size</span><span class="p">)</span> <span class="c1"># add random noise</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;x&#39;</span><span class="p">:</span> <span class="n">xs</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">:</span> <span class="n">ys</span><span class="p">})</span>
<span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;ch12_nonlinear_data_example.csv&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Created </span><span class="si">{0}</span><span class="s2"> many data points and saved them into CSV file.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">xs</span><span class="o">.</span><span class="n">size</span><span class="p">))</span>
</pre></div>
</div>
<div class="output highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Created</span> <span class="mi">100</span> <span class="n">many</span> <span class="n">data</span> <span class="n">points</span> <span class="ow">and</span> <span class="n">saved</span> <span class="n">them</span> <span class="n">into</span> <span class="n">CSV</span> <span class="n">file</span><span class="o">.</span>
</pre></div>
</div>
</div>
<div class="section" id="id2">
<h3><span class="section-number">12.4.2. </span>Download and Visualize Data<a class="headerlink" href="#id2" title="Permalink to this headline">Â¶</a></h3>
<p>Let us download the <code class="docutils literal notranslate"><span class="pre">ch12_linear_data.csv</span></code> file from web so that we
can provide you the experience of a full data analysis pipeline.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span># Let us download our data
!wget -nc https://raw.githubusercontent.com/sinankalkan/CENG240/master/figures/ch12_nonlinear_data.csv

# Import the necessary libraries
import pandas as pd

# Read the file named &#39;ch12_nonlinear_data.csv&#39;
df = pd.read_csv(&#39;ch12_nonlinear_data.csv&#39;)

# Print the CSV file&#39;s contents:
print(&quot;The CSV file contains the following:\n&quot;, df, &quot;\n&quot;)

# Check the types of each column
df.dtypes
</pre></div>
</div>
<div class="output highlight-default notranslate"><div class="highlight"><pre><span></span>--2021-06-21 20:22:36--  https://raw.githubusercontent.com/sinankalkan/CENG240/master/figures/ch12_nonlinear_data.csv
Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...
Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 4064 (4.0K) [text/plain]
Saving to: âch12_nonlinear_data.csvâ

ch12_nonlinear_data 100%[===================&gt;]   3.97K  --.-KB/s    in 0.001s

2021-06-21 20:22:37 (3.44 MB/s) - âch12_nonlinear_data.csvâ saved [4064/4064]

The CSV file contains the following:
     Unnamed: 0          x         y
0            0 -10.000000  3.911998
1            1  -9.797980  1.781296
2            2  -9.595960  1.125093
3            3  -9.393939  0.738523
4            4  -9.191919 -0.343199
..         ...        ...       ...
95          95   9.191919  0.667528
96          96   9.393939 -0.729794
97          97   9.595960  0.643281
98          98   9.797980 -1.533940
99          99  10.000000 -0.760156

[100 rows x 3 columns]
</pre></div>
</div>
<div class="output highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Unnamed</span><span class="p">:</span> <span class="mi">0</span>      <span class="n">int64</span>
<span class="n">x</span>             <span class="n">float64</span>
<span class="n">y</span>             <span class="n">float64</span>
<span class="n">dtype</span><span class="p">:</span> <span class="nb">object</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Let us visualize the data</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">xs</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">][:]</span><span class="o">.</span><span class="n">values</span>
<span class="n">ys</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">][:]</span><span class="o">.</span><span class="n">values</span>

<span class="c1"># Plot y vs. x</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">)</span>

<span class="c1"># Set the labels for x and y axes:</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>

<span class="c1"># Set the title of the figure</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;y vs x&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="output highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Text</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="s1">&#39;y vs x&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="figure align-default">
<img alt="../_images/output_ch12_regression_608a18_15_1.png" src="../_images/output_ch12_regression_608a18_15_1.png" />
</div>
</div>
<div class="section" id="fitting-a-non-linear-function-with-scipy">
<h3><span class="section-number">12.4.3. </span>Fitting a Non-linear Function with SciPy<a class="headerlink" href="#fitting-a-non-linear-function-with-scipy" title="Permalink to this headline">Â¶</a></h3>
<p>For non-linear regression, we will use <code class="docutils literal notranslate"><span class="pre">scipy.optimize.curve_fit</span></code>
which internally performs Non-linear Least-squares Regression.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import optimize module</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">optimize</span>

<span class="k">def</span> <span class="nf">nonlinear_f</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="k">return</span>  <span class="n">a</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span>

<span class="c1"># Fit a linear model:</span>
<span class="n">solution</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">optimize</span><span class="o">.</span><span class="n">curve_fit</span><span class="p">(</span><span class="n">nonlinear_f</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;lm&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The estimated solution is: &quot;</span><span class="p">,</span> <span class="n">solution</span><span class="p">)</span>
</pre></div>
</div>
<div class="output highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">The</span> <span class="n">estimated</span> <span class="n">solution</span> <span class="ow">is</span><span class="p">:</span>  <span class="p">[</span><span class="mf">3.11746172</span> <span class="mf">0.48206522</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="section" id="analyzing-the-solution">
<h3><span class="section-number">12.4.4. </span>Analyzing the Solution<a class="headerlink" href="#analyzing-the-solution" title="Permalink to this headline">Â¶</a></h3>
<p>Similar to our analysis in Section 12.3.4, let us analyze our solution
qualitatively and quantitatively.</p>
<p><strong>1- Qualitative Analysis</strong>. Let us first analyze the found solution
qualitatively.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot y vs. x</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">)</span>

<span class="c1"># Plot the estimated line</span>
<span class="n">plot_func</span><span class="p">(</span><span class="n">nonlinear_f</span><span class="p">,</span> <span class="n">solution</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="s2">&quot;Estimated curve&quot;</span><span class="p">)</span>

<span class="c1"># Plot the correct curve</span>
<span class="n">plot_func</span><span class="p">(</span><span class="n">nonlinear_f</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">xs</span><span class="p">,</span> <span class="s2">&quot;Correct curve&quot;</span><span class="p">)</span>

<span class="c1"># Set the labels for x and y axes:</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>

<span class="c1"># Set the title of the figure</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;y vs x&quot;</span><span class="p">)</span>

<span class="c1"># Legend</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
<div class="output highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">&lt;</span><span class="n">matplotlib</span><span class="o">.</span><span class="n">legend</span><span class="o">.</span><span class="n">Legend</span> <span class="n">at</span> <span class="mh">0x12e7b9b80</span><span class="o">&gt;</span>
</pre></div>
</div>
<div class="figure align-default">
<img alt="../_images/output_ch12_regression_608a18_19_1.png" src="../_images/output_ch12_regression_608a18_19_1.png" />
</div>
<p>Visually, it appears that our estimated solution is a very good fit for
the data and it overlaps nicely with the correct function with which we
had generated the data.</p>
<p><strong>2- Quantitative Analysis</strong>. Now, let us look at some the metrics we
have defined in Section 12.3 to get a better feeling for how good our
fit was:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">estimated_y</span> <span class="o">=</span> <span class="n">nonlinear_f</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="o">*</span><span class="n">solution</span><span class="p">)</span>
<span class="n">correct_y</span> <span class="o">=</span> <span class="n">ys</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MSE Error: &quot;</span><span class="p">,</span> <span class="n">MSE</span><span class="p">(</span><span class="n">estimated_y</span><span class="p">,</span> <span class="n">correct_y</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;RMSE Error: &quot;</span><span class="p">,</span> <span class="n">RMSE</span><span class="p">(</span><span class="n">estimated_y</span><span class="p">,</span> <span class="n">correct_y</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;R-squared Error: &quot;</span><span class="p">,</span> <span class="n">R_squared</span><span class="p">(</span><span class="n">estimated_y</span><span class="p">,</span> <span class="n">correct_y</span><span class="p">))</span>
</pre></div>
</div>
<div class="output highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">MSE</span> <span class="n">Error</span><span class="p">:</span>  <span class="mf">0.6748838046926273</span>
<span class="n">RMSE</span> <span class="n">Error</span><span class="p">:</span>  <span class="mf">0.8215131190021419</span>
<span class="n">R</span><span class="o">-</span><span class="n">squared</span> <span class="n">Error</span><span class="p">:</span>  <span class="mf">0.8540114575179684</span>
</pre></div>
</div>
<p>We see again that we have obtained low error values, despite the noise.
However, we couldnât obtain perfect regression (<span class="math notranslate nohighlight">\(R^2=1\)</span>) since our
data was very noisy.</p>
</div>
</div>
<div class="section" id="important-concepts">
<h2><span class="section-number">12.5. </span>Important Concepts<a class="headerlink" href="#important-concepts" title="Permalink to this headline">Â¶</a></h2>
<p>We would like our readers to have grasped the following crucial concepts
and keywords from this chapter:</p>
<ul class="simple">
<li><p>Regression problem and its uses.</p></li>
<li><p>Least-squares regression.</p></li>
<li><p>Linear vs.Â non-linear regression.</p></li>
<li><p>Linear and non-linear regression with SciPy.</p></li>
<li><p>Qualitatively and quantitatively analyzing a regression solution.</p></li>
</ul>
</div>
<div class="section" id="further-reading">
<h2><span class="section-number">12.6. </span>Further Reading<a class="headerlink" href="#further-reading" title="Permalink to this headline">Â¶</a></h2>
<ul class="simple">
<li><p>The Elements of Statistical Learning, a free book that provides a
good coverage of linear and non-linear regression:
<a class="reference external" href="https://web.stanford.edu/~hastie/ElemStatLearn/">https://web.stanford.edu/~hastie/ElemStatLearn/</a></p></li>
<li><p>Practical Regression and Anova using R, another free book that
provides a practical coverage:
<a class="reference external" href="https://cran.r-project.org/doc/contrib/Faraway-PRA.pdf">https://cran.r-project.org/doc/contrib/Faraway-PRA.pdf</a></p></li>
</ul>
</div>
<div class="section" id="exercises">
<h2><span class="section-number">12.7. </span>Exercises<a class="headerlink" href="#exercises" title="Permalink to this headline">Â¶</a></h2>
<ol class="arabic simple">
<li><p>For clarity, we implemented the error metrics in Section 12.3 using
<code class="docutils literal notranslate"><span class="pre">for</span></code> loops. Re-implement them using NumPy functions without using
explicit <code class="docutils literal notranslate"><span class="pre">for</span></code> or <code class="docutils literal notranslate"><span class="pre">while</span></code> loops.</p></li>
<li><p>Generate 100 random <span class="math notranslate nohighlight">\((x,y)\)</span> values from a non-linear function,
e.g.Â <span class="math notranslate nohighlight">\(y=x^2\)</span>, for <span class="math notranslate nohighlight">\(x\in[-10, 10]\)</span> and use the linear
regression steps in Section 12.3 to regress a linear solution.
Qualitatively and quantitatively analyze the obtained solution.</p></li>
<li><p>Choose your favorite city and download its temperature readings for
two consecutive days from
<a class="reference external" href="https://content.meteoblue.com/en/content/view/full/2879">meteoblue</a>.
Download the readings as CSV files and load them using Pandas. Plot
the data using Matplotlib and see the general shape of the function.
Choose a suitable non-linear function and follow the steps in Section
12.4 to regress a function to the temperature data. Measure also how
good the function represents the temperature readings of the second
day.</p></li>
</ol>
</div>
</div>


        </div>
        <div class="side-doc-outline">
            <div class="side-doc-outline--content"> 
<div class="localtoc">
    <p class="caption">
      <span class="caption-text">Table Of Contents</span>
    </p>
    <ul>
<li><a class="reference internal" href="#">12. An Application: Solving a Simple Regression Problem</a><ul>
<li><a class="reference internal" href="#introduction">12.1. Introduction</a><ul>
<li><a class="reference internal" href="#why-is-regression-important">12.1.1. Why is regression important?</a></li>
<li><a class="reference internal" href="#the-form-of-the-function">12.1.2. The form of the function</a></li>
</ul>
</li>
<li><a class="reference internal" href="#least-squares-regression">12.2. Least-Squares Regression</a></li>
<li><a class="reference internal" href="#linear-regression-with-scipy">12.3. Linear Regression with SciPy</a><ul>
<li><a class="reference internal" href="#create-artificial-data">12.3.1. Create Artificial Data</a></li>
<li><a class="reference internal" href="#download-and-visualize-data">12.3.2. Download and Visualize Data</a></li>
<li><a class="reference internal" href="#fit-a-linear-function-with-scipy">12.3.3. Fit a Linear Function with SciPy</a></li>
<li><a class="reference internal" href="#analyze-the-solution">12.3.4. Analyze the Solution</a></li>
</ul>
</li>
<li><a class="reference internal" href="#non-linear-regression-with-scipy">12.4. Non-linear Regression with SciPy</a><ul>
<li><a class="reference internal" href="#id1">12.4.1. Create Artificial Data</a></li>
<li><a class="reference internal" href="#id2">12.4.2. Download and Visualize Data</a></li>
<li><a class="reference internal" href="#fitting-a-non-linear-function-with-scipy">12.4.3. Fitting a Non-linear Function with SciPy</a></li>
<li><a class="reference internal" href="#analyzing-the-solution">12.4.4. Analyzing the Solution</a></li>
</ul>
</li>
<li><a class="reference internal" href="#important-concepts">12.5. Important Concepts</a></li>
<li><a class="reference internal" href="#further-reading">12.6. Further Reading</a></li>
<li><a class="reference internal" href="#exercises">12.7. Exercises</a></li>
</ul>
</li>
</ul>

</div>
            </div>
        </div>

      <div class="clearer"></div>
    </div><div class="pagenation">
     <a id="button-prev" href="ch11_application_optimization.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="P">
         <i class="pagenation-arrow-L fas fa-arrow-left fa-lg"></i>
         <div class="pagenation-text">
            <span class="pagenation-direction">Previous</span>
            <div>11. An Application: Approximation and Optimization</div>
         </div>
     </a>
  </div>
        
        </main>
    </div>
  </body>
</html>